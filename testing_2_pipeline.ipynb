{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14a4f88d-0e29-44ba-98ad-02b302a074aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from category_encoders.hashing import HashingEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ee72928-1260-4b7a-96d2-91366819d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Semi_time_scaled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb60060-64f7-49f4-8e83-60794af53eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['card_txn_count', 'distance_cust_merchant_km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9784c2b7-5b56-4fe7-b4de-a72690d4f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 to balance and reduce data \n",
    "fraud = data[data['is_fraud'] == 1]\n",
    "non_fraud = data[data['is_fraud'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aad3989a-5adb-45b9-aac0-1b4bca6eea0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Sample non-fraud rows to reduce dataset size and control class imbalance\n",
    "# Here we're keeping a 10:1 ratio of non-fraud to fraud (can change to 5, 20, etc.)\n",
    "# random_state=42  # for reproducibility\n",
    "non_fraud_sampled = non_fraud.sample(n = min(len(non_fraud), len(fraud)*5), random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95bfd643-fcd1-4040-9925-b1dedf8c1b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Combine fraud and sampled non-fraud into one dataset\n",
    "reduced_data = pd.concat([fraud, non_fraud_sampled])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a1995e-f18b-4dd7-bc99-d53e728c6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Shuffle the combined dataset so fraud and non-fraud are mixed\n",
    "reduced_data = reduced_data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f297ef57-6564-4cd1-a28e-164cb360b1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_fraud\n",
      "0    0.833333\n",
      "1    0.166667\n",
      "Name: proportion, dtype: float64\n",
      "(57906, 20)\n"
     ]
    }
   ],
   "source": [
    "# Optional: Check class balance\n",
    "print(reduced_data['is_fraud'].value_counts(normalize=True))  # See class distribution\n",
    "print(reduced_data.shape)  # Check total rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192804a1-dd09-4952-a6e8-8ccb9d2dbbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_fraud\n",
      "0    0.833333\n",
      "1    0.166667\n",
      "Name: proportion, dtype: float64\n",
      "(57906, 20)\n"
     ]
    }
   ],
   "source": [
    "# Optional: Check class balance\n",
    "print(reduced_data['is_fraud'].value_counts(normalize=True))  # See class distribution\n",
    "print(reduced_data.shape)  # Check total rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "964f5bb3-ff5e-473c-b22d-72bfabe1203f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature columns: 19\n",
      "Any missing columns in data? set()\n"
     ]
    }
   ],
   "source": [
    "target = 'is_fraud'\n",
    "\n",
    "# Numeric base (no leakage, no IDs)\n",
    "numeric_base = ['amt', 'city_pop', 'age', 'tr_year']\n",
    "\n",
    "# Cyclic time features\n",
    "cyclic_cols = [\n",
    "    'tr_month_sin', 'tr_month_cos',\n",
    "    'tr_day_sin', 'tr_day_cos',\n",
    "    'tr_hour_sin', 'tr_hour_cos',\n",
    "    'tr_minute_sin', 'tr_minute_cos'\n",
    "]\n",
    "\n",
    "# Low-cardinality categoricals → OneHot\n",
    "low_card_cat = ['category', 'gender', 'state']\n",
    "\n",
    "# High-cardinality categoricals → Hashing (merchant, city, job, zip)\n",
    "high_card_cat = ['merchant', 'city', 'job', 'zip']\n",
    "\n",
    "# Sanity check: all features accounted for\n",
    "X_cols = numeric_base + cyclic_cols + low_card_cat + high_card_cat\n",
    "print(\"Number of feature columns:\", len(X_cols))\n",
    "print(\"Any missing columns in data?\",\n",
    "      set(data.drop(columns=[target]).columns) - set(X_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8523c5dc-7dbf-47ef-8bd0-5e58b14c3cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46324, 19) (46324,)\n",
      "(11582, 19) (11582,)\n"
     ]
    }
   ],
   "source": [
    "X = reduced_data[X_cols].copy()\n",
    "y = reduced_data[target].astype(int)   # ensure 0/1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b1d33b5-7c83-4758-a355-8c168cb4616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numeric features (only base numeric, NOT cyclic)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# One-hot for low-card categorical\n",
    "low_cat_transformer = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Hashing for high-card categorical\n",
    "high_cat_transformer = Pipeline(steps=[\n",
    "    ('hash', HashingEncoder(n_components=64))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea9e9fe-cadc-4cfa-ac9c-6e9c83dae233",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_non_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_base),\n",
    "        ('cyclic', 'passthrough', cyclic_cols),\n",
    "        ('low_cat', low_cat_transformer, low_card_cat),\n",
    "        ('high_cat', high_cat_transformer, high_card_cat),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a0b9086-223d-467e-b11e-7bf3badcbd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92      9652\n",
      "           1       0.58      0.80      0.68      1930\n",
      "\n",
      "    accuracy                           0.87     11582\n",
      "   macro avg       0.77      0.84      0.80     11582\n",
      "weighted avg       0.89      0.87      0.88     11582\n",
      "\n",
      "ROC_AUC: 0.9301963779957011\n",
      "Confusion matrix:\n",
      " [[8552 1100]\n",
      " [ 385 1545]]\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(\n",
    "    max_iter=100,\n",
    "    class_weight='balanced',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "log_pipe = Pipeline(steps=[\n",
    "    ('preprocess', preprocess_non_tree),\n",
    "    ('model', log_reg)\n",
    "])\n",
    "\n",
    "log_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lr  = log_pipe.predict(X_test)\n",
    "y_proba_lr = log_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"ROC_AUC:\", roc_auc_score(y_test, y_proba_lr))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "641a6de5-f8f0-4668-8762-214e613ded44",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_tree = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_base + cyclic_cols),\n",
    "        ('low_cat', low_cat_transformer, low_card_cat),\n",
    "        ('high_cat', high_cat_transformer, high_card_cat),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d958bd2c-9c49-4ba7-9d60-4f46dd33752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      9652\n",
      "           1       0.82      0.98      0.89      1930\n",
      "\n",
      "    accuracy                           0.96     11582\n",
      "   macro avg       0.91      0.97      0.93     11582\n",
      "weighted avg       0.97      0.96      0.96     11582\n",
      "\n",
      "ROC_AUC: 0.9888263647470845\n",
      "Confusion matrix:\n",
      " [[9232  420]\n",
      " [  35 1895]]\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    max_depth=10,\n",
    "    criterion='gini',\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_pipe = Pipeline(steps=[\n",
    "    ('preprocess', preprocess_tree),\n",
    "    ('model', dt)\n",
    "])\n",
    "\n",
    "dt_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt  = dt_pipe.predict(X_test)\n",
    "y_proba_dt = dt_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Decision Tree ===\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(\"ROC_AUC:\", roc_auc_score(y_test, y_proba_dt))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b59cf80-6a6c-4ed5-a624-0ccf98e0532e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      9652\n",
      "           1       0.98      0.85      0.91      1930\n",
      "\n",
      "    accuracy                           0.97     11582\n",
      "   macro avg       0.98      0.92      0.95     11582\n",
      "weighted avg       0.97      0.97      0.97     11582\n",
      "\n",
      "ROC_AUC: 0.9897810649998176\n",
      "Confusion matrix:\n",
      " [[9619   33]\n",
      " [ 287 1643]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=30,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight='balanced_subsample',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_pipe = Pipeline(steps=[\n",
    "    ('preprocess', preprocess_tree),\n",
    "    ('model', rf)\n",
    "])\n",
    "\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf  = rf_pipe.predict(X_test)\n",
    "y_proba_rf = rf_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Random Forest ===\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC_AUC:\", roc_auc_score(y_test, y_proba_rf))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e7646d3-4a7a-466f-81af-cb218b9b4db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dummy Model ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91      9652\n",
      "           1       0.00      0.00      0.00      1930\n",
      "\n",
      "    accuracy                           0.83     11582\n",
      "   macro avg       0.42      0.50      0.45     11582\n",
      "weighted avg       0.69      0.83      0.76     11582\n",
      "\n",
      "ROC_AUC: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patid\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\patid\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\patid\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "dummy = DummyClassifier(strategy='most_frequent') \n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dummy = dummy.predict(X_test)\n",
    "y_proba_dummy = dummy.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"=== Dummy Model ===\")\n",
    "print(classification_report(y_test, y_pred_dummy))\n",
    "print(\"ROC_AUC:\", roc_auc_score(y_test, y_proba_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ed7557-9477-48b0-8bcb-f9c4cc331c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618aa2ed-1d77-4c09-a4f3-fc6bd81c60d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
